#!/usr/bin/env python3
"""
ğŸš€ å¢å¼ºç‰ˆTaskQ - é›†æˆRedis + MongoDBæ··åˆå­˜å‚¨
============================================

è‡ªåŠ¨å†…å­˜å‹åŠ›æ£€æµ‹ï¼Œæ™ºèƒ½æ•°æ®è¿ç§»ï¼Œæ— ç¼CRUDæ“ä½œ
"""

import time
import json
import logging
from typing import Any, Dict, List, Optional, Union
from hybrid_storage import HybridStorage, StorageConfig

logger = logging.getLogger(__name__)

class HybridTaskQ:
    """å¢å¼ºç‰ˆTaskQï¼Œæ”¯æŒRedis + MongoDBæ··åˆå­˜å‚¨"""
    
    def __init__(self, 
                 name: str, 
                 uri: str = "http://localhost:9000",
                 redis_uri: str = "redis://localhost:6379",
                 mongodb_uri: str = "mongodb://localhost:27017",
                 database: str = "zaku_hybrid",
                 collection: str = None,
                 memory_threshold: float = 0.8,
                 memory_check_interval: int = 5,
                 batch_size: int = 100):
        """
        åˆå§‹åŒ–æ··åˆå­˜å‚¨TaskQ
        
        Args:
            name: é˜Ÿåˆ—åç§°
            uri: ZakuæœåŠ¡å™¨URI
            redis_uri: Redisè¿æ¥URI
            mongodb_uri: MongoDBè¿æ¥URI
            database: MongoDBæ•°æ®åº“å
            collection: MongoDBé›†åˆåï¼ˆé»˜è®¤ä½¿ç”¨é˜Ÿåˆ—åï¼‰
            memory_threshold: Rediså†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼
            memory_check_interval: å†…å­˜æ£€æŸ¥é—´éš”
            batch_size: æ‰¹é‡æ“ä½œå¤§å°
        """
        self.name = name
        self.uri = uri
        self.collection = collection or f"queue_{name}"
        
        # é…ç½®æ··åˆå­˜å‚¨
        config = StorageConfig(
            redis_uri=redis_uri,
            mongodb_uri=mongodb_uri,
            database=database,
            collection=self.collection,
            memory_threshold=memory_threshold,
            memory_check_interval=memory_check_interval,
            batch_size=batch_size
        )
        
        # åˆå§‹åŒ–æ··åˆå­˜å‚¨
        self.storage = HybridStorage(config)
        
        # é˜Ÿåˆ—ç›¸å…³
        self.prefix = f"zaku:queue:{name}:"
        self.task_prefix = f"{self.prefix}task:"
        self.meta_prefix = f"{self.prefix}meta:"
        
        logger.info(f"æ··åˆå­˜å‚¨TaskQåˆå§‹åŒ–æˆåŠŸ: {name}")
    
    def _generate_key(self, task_id: str = None) -> str:
        """ç”Ÿæˆå­˜å‚¨é”®"""
        if task_id:
            return f"{self.task_prefix}{task_id}"
        return f"{self.meta_prefix}counter"
    
    def _generate_task_id(self) -> str:
        """ç”Ÿæˆä»»åŠ¡ID"""
        return f"{int(time.time() * 1000)}_{id(self)}"
    
    def add(self, data: Any, priority: int = 0) -> str:
        """
        æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—
        
        Args:
            data: ä»»åŠ¡æ•°æ®
            priority: ä»»åŠ¡ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
            
        Returns:
            ä»»åŠ¡ID
        """
        task_id = self._generate_task_id()
        task_data = {
            "id": task_id,
            "data": data,
            "priority": priority,
            "created_at": time.time(),
            "status": "pending"
        }
        
        key = self._generate_key(task_id)
        if self.storage.add(key, task_data):
            logger.info(f"ä»»åŠ¡æ·»åŠ æˆåŠŸ: {task_id}")
            return task_id
        else:
            raise Exception(f"ä»»åŠ¡æ·»åŠ å¤±è´¥: {task_id}")
    
    def take(self, timeout: float = None) -> Optional[Any]:
        """
        ä»é˜Ÿåˆ—ä¸­å–å‡ºä»»åŠ¡
        
        Args:
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            ä»»åŠ¡æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰ä»»åŠ¡è¿”å›None
        """
        start_time = time.time()
        
        while True:
            # è·å–æ‰€æœ‰ä»»åŠ¡é”®
            task_keys = self._get_all_task_keys()
            
            if not task_keys:
                if timeout and (time.time() - start_time) > timeout:
                    logger.debug("ç­‰å¾…ä»»åŠ¡è¶…æ—¶")
                    return None
                time.sleep(0.1)  # çŸ­æš‚ç­‰å¾…
                continue
            
            # æŒ‰ä¼˜å…ˆçº§æ’åºä»»åŠ¡
            sorted_tasks = self._sort_tasks_by_priority(task_keys)
            
            for task_key in sorted_tasks:
                task_data = self.storage.get(task_key)
                if task_data and task_data.get("status") == "pending":
                    # æ ‡è®°ä»»åŠ¡ä¸ºå¤„ç†ä¸­
                    task_data["status"] = "processing"
                    task_data["taken_at"] = time.time()
                    self.storage.add(task_key, task_data)
                    
                    logger.info(f"ä»»åŠ¡å–å‡ºæˆåŠŸ: {task_data['id']}")
                    return task_data["data"]
            
            # æ²¡æœ‰å¯ç”¨çš„ä»»åŠ¡
            if timeout and (time.time() - start_time) > timeout:
                logger.debug("ç­‰å¾…ä»»åŠ¡è¶…æ—¶")
                return None
            
            time.sleep(0.1)  # çŸ­æš‚ç­‰å¾…
    
    def _get_all_task_keys(self) -> List[str]:
        """è·å–æ‰€æœ‰ä»»åŠ¡é”®"""
        try:
            # ä½¿ç”¨æ··åˆå­˜å‚¨çš„é”®æ‰«æåŠŸèƒ½
            all_keys = self.storage.scan_keys(f"{self.task_prefix}*")
            return all_keys
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡é”®å¤±è´¥: {e}")
            return []
    
    def _sort_tasks_by_priority(self, task_keys: List[str]) -> List[str]:
        """æŒ‰ä¼˜å…ˆçº§æ’åºä»»åŠ¡"""
        tasks_with_priority = []
        
        for key in task_keys:
            task_data = self.storage.get(key)
            if task_data:
                tasks_with_priority.append((key, task_data.get("priority", 0)))
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        sorted_tasks = sorted(tasks_with_priority, key=lambda x: x[1])
        return [task[0] for task in sorted_tasks]
    
    def complete(self, task_id: str) -> bool:
        """
        æ ‡è®°ä»»åŠ¡ä¸ºå®Œæˆ
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        key = self._generate_key(task_id)
        task_data = self.storage.get(key)
        
        if task_data:
            task_data["status"] = "completed"
            task_data["completed_at"] = time.time()
            
            if self.storage.add(key, task_data):
                logger.info(f"ä»»åŠ¡æ ‡è®°å®Œæˆ: {task_id}")
                return True
        
        logger.warning(f"ä»»åŠ¡æ ‡è®°å®Œæˆå¤±è´¥: {task_id}")
        return False
    
    def fail(self, task_id: str, error: str = None) -> bool:
        """
        æ ‡è®°ä»»åŠ¡ä¸ºå¤±è´¥
        
        Args:
            task_id: ä»»åŠ¡ID
            error: é”™è¯¯ä¿¡æ¯
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        key = self._generate_key(task_id)
        task_data = self.storage.get(key)
        
        if task_data:
            task_data["status"] = "failed"
            task_data["failed_at"] = time.time()
            task_data["error"] = error
            
            if self.storage.add(key, task_data):
                logger.info(f"ä»»åŠ¡æ ‡è®°å®Œæˆ: {task_id}")
                return True
        
        logger.warning(f"ä»»åŠ¡æ ‡è®°å¤±è´¥å¤±è´¥: {task_id}")
        return False
    
    def delete(self, task_id: str) -> bool:
        """
        åˆ é™¤ä»»åŠ¡
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        key = self._generate_key(task_id)
        if self.storage.delete(key):
            logger.info(f"ä»»åŠ¡åˆ é™¤æˆåŠŸ: {task_id}")
            return True
        
        logger.warning(f"ä»»åŠ¡åˆ é™¤å¤±è´¥: {task_id}")
        return False
    
    def get_task_info(self, task_id: str) -> Optional[Dict]:
        """
        è·å–ä»»åŠ¡ä¿¡æ¯
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            ä»»åŠ¡ä¿¡æ¯å­—å…¸
        """
        key = self._generate_key(task_id)
        return self.storage.get(key)
    
    def get_queue_stats(self) -> Dict[str, Any]:
        """
        è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
        """
        stats = self.storage.get_storage_stats()
        stats.update({
            "queue_name": self.name,
            "queue_uri": self.uri
        })
        return stats
    
    def get_task_count_by_status(self) -> Dict[str, int]:
        """
        è·å–å„çŠ¶æ€çš„ä»»åŠ¡æ•°é‡
        
        Returns:
            çŠ¶æ€ç»Ÿè®¡å­—å…¸
        """
        status_counts = {"pending": 0, "processing": 0, "completed": 0, "failed": 0}
        
        try:
            task_keys = self._get_all_task_keys()
            for key in task_keys:
                task_data = self.storage.get(key)
                if task_data:
                    status = task_data.get("status", "unknown")
                    status_counts[status] = status_counts.get(status, 0) + 1
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€ç»Ÿè®¡å¤±è´¥: {e}")
        
        return status_counts
    
    def reset(self) -> bool:
        """
        é‡ç½®é˜Ÿåˆ—ï¼ˆæ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼‰
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if self.storage.clear():
            logger.info(f"é˜Ÿåˆ—é‡ç½®æˆåŠŸ: {self.name}")
            return True
        
        logger.warning(f"é˜Ÿåˆ—é‡ç½®å¤±è´¥: {self.name}")
        return False
    
    def cleanup_completed_tasks(self, max_age_hours: int = 24) -> int:
        """
        æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
        
        Args:
            max_age_hours: æœ€å¤§ä¿ç•™æ—¶é—´ï¼ˆå°æ—¶ï¼‰
            
        Returns:
            æ¸…ç†çš„ä»»åŠ¡æ•°é‡
        """
        cleaned_count = 0
        cutoff_time = time.time() - (max_age_hours * 3600)
        
        try:
            task_keys = self._get_all_task_keys()
            for key in task_keys:
                task_data = self.storage.get(key)
                if task_data:
                    status = task_data.get("status")
                    completed_at = task_data.get("completed_at", 0)
                    
                    # æ¸…ç†å·²å®Œæˆä¸”è¶…è¿‡ä¿ç•™æ—¶é—´çš„ä»»åŠ¡
                    if (status in ["completed", "failed"] and 
                        completed_at < cutoff_time):
                        if self.storage.delete(key):
                            cleaned_count += 1
            
            if cleaned_count > 0:
                logger.info(f"æ¸…ç†äº† {cleaned_count} ä¸ªå·²å®Œæˆçš„ä»»åŠ¡")
                
        except Exception as e:
            logger.error(f"æ¸…ç†å·²å®Œæˆä»»åŠ¡å¤±è´¥: {e}")
        
        return cleaned_count
    
    def migrate_tasks(self, target_storage: str = "auto") -> Dict[str, int]:
        """
        è¿ç§»ä»»åŠ¡åˆ°æŒ‡å®šå­˜å‚¨
        
        Args:
            target_storage: ç›®æ ‡å­˜å‚¨ ("redis", "mongodb", "auto")
            
        Returns:
            è¿ç§»ç»Ÿè®¡ä¿¡æ¯
        """
        migration_stats = {"to_redis": 0, "to_mongodb": 0}
        
        try:
            if target_storage == "auto":
                # è‡ªåŠ¨è¿ç§»ï¼šæ ¹æ®å†…å­˜å‹åŠ›å†³å®š
                if self.storage.redis_storage and self.storage.redis_storage.is_memory_pressure_high():
                    # Rediså†…å­˜å‹åŠ›å¤§ï¼Œè¿ç§»åˆ°MongoDB
                    task_keys = self._get_all_task_keys()
                    migration_stats["to_mongodb"] = self.storage.migrate_to_mongodb(task_keys)
                else:
                    # Rediså†…å­˜å‹åŠ›ä¸å¤§ï¼Œè¿ç§»åˆ°Redis
                    task_keys = self._get_all_task_keys()
                    migration_stats["to_redis"] = self.storage.migrate_to_redis(task_keys)
            
            elif target_storage == "redis":
                task_keys = self._get_all_task_keys()
                migration_stats["to_redis"] = self.storage.migrate_to_redis(task_keys)
            
            elif target_storage == "mongodb":
                task_keys = self._get_all_task_keys()
                migration_stats["to_mongodb"] = self.storage.migrate_to_mongodb(task_keys)
            
            logger.info(f"ä»»åŠ¡è¿ç§»å®Œæˆ: {migration_stats}")
            
        except Exception as e:
            logger.error(f"ä»»åŠ¡è¿ç§»å¤±è´¥: {e}")
        
        return migration_stats
    
    def publish(self, message: Any, topic: str) -> int:
        """
        å‘å¸ƒæ¶ˆæ¯åˆ°ä¸»é¢˜ï¼ˆå…¼å®¹åŸæœ‰APIï¼‰
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
            topic: ä¸»é¢˜åç§°
            
        Returns:
            è®¢é˜…è€…æ•°é‡
        """
        # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨Zakuçš„å‘å¸ƒè®¢é˜…åŠŸèƒ½
        logger.info(f"å‘å¸ƒæ¶ˆæ¯åˆ°ä¸»é¢˜: {topic}")
        return 1
    
    def subscribe_one(self, topic: str, timeout: float = None) -> Optional[Any]:
        """
        è®¢é˜…ä¸»é¢˜çš„å•æ¡æ¶ˆæ¯ï¼ˆå…¼å®¹åŸæœ‰APIï¼‰
        
        Args:
            topic: ä¸»é¢˜åç§°
            timeout: è¶…æ—¶æ—¶é—´
            
        Returns:
            æ¶ˆæ¯å†…å®¹
        """
        # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨Zakuçš„å‘å¸ƒè®¢é˜…åŠŸèƒ½
        logger.info(f"è®¢é˜…ä¸»é¢˜: {topic}")
        return None
    
    def subscribe_stream(self, topic: str, timeout: float = None):
        """
        è®¢é˜…ä¸»é¢˜çš„æ¶ˆæ¯æµï¼ˆå…¼å®¹åŸæœ‰APIï¼‰
        
        Args:
            topic: ä¸»é¢˜åç§°
            timeout: è¶…æ—¶æ—¶é—´
            
        Yields:
            æ¶ˆæ¯å†…å®¹
        """
        # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨Zakuçš„å‘å¸ƒè®¢é˜…åŠŸèƒ½
        logger.info(f"è®¢é˜…ä¸»é¢˜æµ: {topic}")
        return []

class HybridTaskQFactory:
    """æ··åˆå­˜å‚¨TaskQå·¥å‚ç±»"""
    
    @staticmethod
    def create(name: str, 
               redis_uri: str = "redis://localhost:6379",
               mongodb_uri: str = "mongodb://localhost:27017",
               **kwargs) -> HybridTaskQ:
        """
        åˆ›å»ºæ··åˆå­˜å‚¨TaskQå®ä¾‹
        
        Args:
            name: é˜Ÿåˆ—åç§°
            redis_uri: Redisè¿æ¥URI
            mongodb_uri: MongoDBè¿æ¥URI
            **kwargs: å…¶ä»–é…ç½®å‚æ•°
            
        Returns:
            HybridTaskQå®ä¾‹
        """
        return HybridTaskQ(
            name=name,
            redis_uri=redis_uri,
            mongodb_uri=mongodb_uri,
            **kwargs
        )

# å…¼å®¹åŸæœ‰TaskQçš„åˆ«å
TaskQ = HybridTaskQ 